{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "622225bc-b011-40d1-a79f-6242f59be99d",
   "metadata": {},
   "source": [
    "feature engineering to prepare training data for XGBoost and logistic regression.\n",
    "1. Build a switcher where I can turn on and off each feature engineering step. In the notebook. should I still build the feature engineering steps on top of each other? i.e. ohe on imputed df.\n",
    "2. Outliers: We don't want to remove it, leaving them untouched for XGBoost. However, logistic regression is more sensitive to outliers, so we need to handle it.\n",
    "3. Missing values: XGBoost is good at dealing missing values. However, missing values are still imputed to prepare for other algorithm and compare model performance. \n",
    "4. Scaling: scale the data with robust scaler because there are significant outliers, still scaling is not very helpful for xgboost but we add it case we are trying other algorithms.\n",
    "5. Mutual information evaluation after all the preprocessing to find significant input features. \n",
    "6. Build a base model evalution for the dataset, which is evaluated by recall@5% because it's highly imbalanced. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60767c46-e67b-4dc2-8a6d-9845f4989725",
   "metadata": {},
   "source": [
    "# 1. Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cc092e49-eb61-4a02-97f9-ee85b66858e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting setups\n"
     ]
    }
   ],
   "source": [
    "print(\"Starting setups\")\n",
    "import sys\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cac7f9a4-40a5-4e85-9c7e-bcd0f8320382",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dir_path is /Users/zoe/Documents/Bank-account-fraud/code/feature_engineering\n",
      "parent_dir is /Users/zoe/Documents/Bank-account-fraud/code\n",
      "home_dir is /Users/zoe/Documents/Bank-account-fraud\n"
     ]
    }
   ],
   "source": [
    "dir_path = os.getcwd()\n",
    "parent_dir = os.path.dirname(dir_path)\n",
    "home_dir = os.path.dirname(parent_dir)\n",
    "print(\"dir_path is\", dir_path)\n",
    "print(\"parent_dir is\", parent_dir)\n",
    "print(\"home_dir is\", home_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4ef1926a-a3a4-48ac-8ca7-dbe913a9729d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/zoe/Documents/Bank-account-fraud/params.yaml\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'data_location': '/data',\n",
       " 'output_location': '/output',\n",
       " 'code_location': '/code'}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import yaml\n",
    "print(home_dir+'/params.yaml')\n",
    "with open(home_dir+'/params.yaml', 'r') as file:\n",
    "    params = yaml.safe_load(file)\n",
    "params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c3b40847-6cbe-4822-9690-2394a53fae3f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data is stored at /Users/zoe/Documents/Bank-account-fraud/data\n"
     ]
    }
   ],
   "source": [
    "data_folder = home_dir+params['data_location']\n",
    "print('Data is stored at', data_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5ea7c6d9-d28f-4080-99df-24325cc6cd8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current configuration for feature engineering is: {'impute': True, 'one_hot_encoding': True, 'smote': True, 'smote_oversample_ratio': 0.8, 'smote_undersample_ratio': 1.0, 'robust_scaler': True, 'binning': True, 'outlier_handling': False, 'mutual_information': False, 'chi2_test': False}\n"
     ]
    }
   ],
   "source": [
    "with open(dir_path+\"/feature_flag.yaml\", \"r\") as file:\n",
    "    config = yaml.safe_load(file)[\"feature_engineering\"]\n",
    "\n",
    "print(f\"Current configuration for feature engineering is: {config}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ab0c6fb-1024-48f5-98ef-fb3c54cd12bc",
   "metadata": {},
   "source": [
    "## 1.1 Import libraries and reading data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "71999b8a-6225-4e5e-baf9-b9508e253943",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Importing packages and reading data...\n"
     ]
    }
   ],
   "source": [
    "print(\"Importing packages and reading data...\")\n",
    "\n",
    "sys.path.append(os.path.abspath(\"feature_engineering\"))\n",
    "from preprocessing import *\n",
    "\n",
    "import pandas as pd\n",
    "pd.set_option('display.max_columns', 500)\n",
    "\n",
    "import warnings as wr\n",
    "wr.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5f4ee78b-f5c4-4f9c-a8d3-ffe479ce92d2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/opt/homebrew/Cellar/python@3.11/3.11.10/Frameworks/Python.framework/Versions/3.11/lib/python311.zip',\n",
       " '/opt/homebrew/Cellar/python@3.11/3.11.10/Frameworks/Python.framework/Versions/3.11/lib/python3.11',\n",
       " '/opt/homebrew/Cellar/python@3.11/3.11.10/Frameworks/Python.framework/Versions/3.11/lib/python3.11/lib-dynload',\n",
       " '',\n",
       " '/opt/homebrew/lib/python3.11/site-packages']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sys.path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3861ac05-ff21-424a-a351-9285eeb42783",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_base = pd.read_csv(f\"{data_folder}/Base_backup.csv\", header=0)\n",
    "df = df_base.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07fedc08-12c2-417e-bf08-2d362c90b01f",
   "metadata": {},
   "source": [
    "## 1.2 Drop features with no variance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "58137586-3887-4a74-961c-40cad6d9183c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dropping the constant features: ['device_fraud_count']\n"
     ]
    }
   ],
   "source": [
    "constant_feature =[]\n",
    "for x in df.columns:\n",
    "    if df[x].nunique() == 1:\n",
    "        constant_feature.append(x)\n",
    "print(\"Dropping the constant features:\", constant_feature)       \n",
    "df = drop_columns(df, df[constant_feature])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3cb48e6-24f3-48dd-b29a-f179a6943080",
   "metadata": {},
   "source": [
    "### 1.3 Change the dataype of binary features into type boolean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7e25dfa0-06a7-40fc-a394-8cbbe8acba0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Changing the dataype of binary features into type boolean\n",
      "fraud_bool            bool\n",
      "email_is_free         bool\n",
      "phone_home_valid      bool\n",
      "phone_mobile_valid    bool\n",
      "has_other_cards       bool\n",
      "foreign_request       bool\n",
      "keep_alive_session    bool\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(\"Changing the dataype of binary features into type boolean\")\n",
    "binary_features = df.columns[df.nunique() == 2].tolist()\n",
    "\n",
    "binary_features.remove('source')\n",
    "# Convert these features\"to boolean\n",
    "df[binary_features] = df[binary_features].astype(bool)\n",
    "\n",
    "# Verify changes\n",
    "print(df[binary_features].dtypes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afbad7ac-6f1e-4359-9e82-fc7d882c95e3",
   "metadata": {},
   "source": [
    "## 1.3 Train test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1d475a78-740e-4faa-ae2f-37ae8cdc7b57",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "splitting train/test sets\n",
      "Training set (X_train) before feature engineering: (800000, 30)\n",
      "Test set (X_test) before feature engineering: (200000, 30)\n",
      "Training set (y_train) before feature engineering: (800000,)\n",
      "Test set (y_test) before feature engineering: (200000,)\n",
      "Categorical features before feature engineering: ['income', 'customer_age', 'payment_type', 'employment_status', 'email_is_free', 'housing_status', 'phone_home_valid', 'phone_mobile_valid', 'has_other_cards', 'proposed_credit_limit', 'foreign_request', 'source', 'device_os', 'keep_alive_session', 'device_distinct_emails_8w', 'month']\n",
      "Numerical features before feature engineering: ['name_email_similarity', 'prev_address_months_count', 'current_address_months_count', 'days_since_request', 'intended_balcon_amount', 'zip_count_4w', 'velocity_6h', 'velocity_24h', 'velocity_4w', 'bank_branch_count_8w', 'date_of_birth_distinct_emails_4w', 'credit_risk_score', 'bank_months_count', 'session_length_in_minutes']\n"
     ]
    }
   ],
   "source": [
    "print(\"splitting train/test sets\")\n",
    "y = df['fraud_bool']\n",
    "X = df.drop(columns=['fraud_bool'], axis = 1)\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "test_size = 0.2\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_size, random_state=42)\n",
    "\n",
    "print(f\"Training set (X_train) before feature engineering: {X_train.shape}\")\n",
    "print(f\"Test set (X_test) before feature engineering: {X_test.shape}\")\n",
    "print(f\"Training set (y_train) before feature engineering: {y_train.shape}\")\n",
    "print(f\"Test set (y_test) before feature engineering: {y_test.shape}\")\n",
    "\n",
    "categorical_features, numerical_features = split_num_cat(df)\n",
    "print('Categorical features before feature engineering:', categorical_features)\n",
    "print('Numerical features before feature engineering:', numerical_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "170fe7a5-07a1-406c-97c5-4a7c335f1cae",
   "metadata": {},
   "source": [
    "## 2. Switcher"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14f90982-3843-4dda-a6cf-20c1cf0db192",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Start feature engineering steps...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4303d85d-3a85-419d-8216-c6e38d501f53",
   "metadata": {},
   "outputs": [],
   "source": [
    "if config[\"impute\"]:\n",
    "    print(\"Applying imputation for missing values...\")\n",
    "    X_train, X_test = impute_missing_values(X_train, X_test)\n",
    "else:\n",
    "    print(\"Not applying imputation.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00c95f01-cecf-4e11-97d5-e728f3c2c443",
   "metadata": {},
   "outputs": [],
   "source": [
    "if config[\"one_hot_encoding\"]:\n",
    "    print(\"Applying one-hot encoding...\")\n",
    "    X_train, X_test = one_hot_encode(X_train, X_test)\n",
    "else:\n",
    "    print(\"Not applying one hot encoder.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d5dd5d4-99bb-4487-b1af-680f23b7da95",
   "metadata": {},
   "outputs": [],
   "source": [
    "if config[\"binning\"]:\n",
    "    print(\"Applying binning...\")\n",
    "    X_train, X_test = bin_bank_months_count(X_train, X_test, y_train)\n",
    "else:\n",
    "    print(\"Not applying binning.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e02b603e-a4be-4b17-8197-b16dc1b47456",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "if config[\"robust_scaler\"]:\n",
    "    print(\"Applying robust scaling...\")\n",
    "    X_train, X_test = robust_scaler(X_train, X_test)\n",
    "else:\n",
    "    print(\"Not applying scaler.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be3dffff-558d-4630-8512-8fc26e21c9bd",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "if config[\"outlier_handling\"]:\n",
    "    print(\"Removing outliers...\")\n",
    "    X_train, y_train = handle_outliers(X_train, y_train)\n",
    "else:\n",
    "    print(\"Not handling outliers\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5faf2942-8f4c-4a4a-bd51-d853b87fa8f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "if config[\"smote\"]:\n",
    "    print(\"Perfoming SMOTE to handle class imbalance\")\n",
    "    X_train, y_train = smote(X_train, y_train, over_ratio=0.7, under_ratio=0.9)\n",
    "else:\n",
    "    print(\"Not applying SMOTE\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8dc5787-b1d8-4fd2-ba8e-99b254de8934",
   "metadata": {},
   "outputs": [],
   "source": [
    "if config[\"mutual_information\"]:\n",
    "    print(\"Calculating mutual information scores based on the final training set\")\n",
    "    mi_scores = mutual_information(X_train, y_train)\n",
    "else:\n",
    "    print(\"Not calculating mutua information\")\n",
    "    \n",
    "if config[\"chi2_test\"]:\n",
    "    print(\"Calculating chi2 based on the final training set\")\n",
    "    chi2_results = chi2_test(X_train, y_train)\n",
    "else:\n",
    "    print(\"Not calculating chi2\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab01dd72-2191-4c31-8bf1-7b0dc3219cc4",
   "metadata": {},
   "source": [
    "# Save the final output "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb25ba3f-9a15-4ffa-9b59-f1d81992a424",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Exporting final dataset...\")\n",
    "export_final_df(X_train, y_train, X_test, y_test, data_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5c19d0b-b86f-4790-b50f-4bf4318f6c96",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f082853a-f700-489d-8caf-16222f3016e4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
