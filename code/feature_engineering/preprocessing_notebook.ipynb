{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f5dc5259-9919-42f1-ac5d-f53e0d899490",
   "metadata": {},
   "source": [
    "# Helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bbe153fe-5e0c-45fc-aad5-b5def5ea4cd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# split categorical and numerical features\n",
    "def split_num_cat(df):\n",
    "    \"\"\"\n",
    "    Function to split columns into two, one having categorical features and another having numerical feautures\n",
    "    Parameters\n",
    "    ----------\n",
    "    df : dataframe\n",
    "            pass in full dataframe\n",
    "    ----------\n",
    "    Returns: \n",
    "        a list of categorical features\n",
    "        a list of numerical features\n",
    "    \"\"\"\n",
    "    categorical_features = []\n",
    "    numerical_features = []\n",
    "\n",
    "    for x in df.columns: \n",
    "        if df[x].nunique() > 12:\n",
    "            numerical_features.append(x)\n",
    "        elif df[x].nunique() >=2:\n",
    "            categorical_features.append(x)\n",
    "\n",
    "    if 'fraud_bool' in categorical_features:\n",
    "        categorical_features.remove('fraud_bool')\n",
    "    \n",
    "    return categorical_features, numerical_features\n",
    "\n",
    "def drop_columns(df, column_name):\n",
    "    \"\"\"\n",
    "    Function to delete the list of columns \n",
    "    Parameters\n",
    "    ----------\n",
    "    df : dataframe\n",
    "            pass in full dataframe\n",
    "    column_name : list\n",
    "            pass in list of full column\n",
    "    ----------\n",
    "    Returns: Dataframe\n",
    "    \"\"\"\n",
    "    df = df.drop(column_name, axis=1)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "398f9a65-1dc3-45b0-aefa-cbd8dc9b2c7b",
   "metadata": {},
   "source": [
    "# 2. Handle missing values¶"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22270262-397c-43e2-a65e-be175a424fd5",
   "metadata": {},
   "source": [
    "XGBoost supports missing values by default. In tree algorithms, branch directions for missing values are learned during training. And the gblinear booster treats missing values as zeros.\n",
    "\n",
    "We still choose to handle missing values in case of we are using any other types of models. \n",
    "Also for features with high percentage of missing values, we choose to add an additional column to indicate where the value is missing, so the model can still learn from missing values. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "367e7238-7e05-4d8b-b37d-cc72cdf90db6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def impute_missing_values(X_train, X_test):\n",
    "    \"\"\"\n",
    "    Imputes missing values in X_train and X_test based on predefined rules.\n",
    "\n",
    "    - Replaces `-1` values with `NaN`.\n",
    "    - Median imputation for specified columns.\n",
    "    - Bank months count missing values replaced with `0` and tracked in a new indicator column.\n",
    "    - Previous address months count imputed based on address bucket medians.\n",
    "\n",
    "    Parameters:\n",
    "    X_train (pd.DataFrame): Training dataset\n",
    "    X_test (pd.DataFrame): Test dataset\n",
    "\n",
    "    Returns:\n",
    "    pd.DataFrame, pd.DataFrame: Imputed training and test datasets\n",
    "    \"\"\"\n",
    "\n",
    "    # Identify columns with missing values represented by -1\n",
    "    missing_value_cols = [col for col in X_train.columns if (X_train[col].min() == -1)]\n",
    "    print(\"Features with missing values represented by -1:\")\n",
    "    print(missing_value_cols)\n",
    "\n",
    "    # Replace -1 values with NaN\n",
    "    X_train[missing_value_cols] = X_train[missing_value_cols].replace(-1, np.nan)\n",
    "    X_test[missing_value_cols] = X_test[missing_value_cols].replace(-1, np.nan)\n",
    "\n",
    "    # Create copies to avoid modifying the original data\n",
    "    df_train_imputed = X_train.copy()\n",
    "    df_test_imputed = X_test.copy()\n",
    "\n",
    "    # Step 1: Median Imputation for selected columns\n",
    "    columns_to_impute = ['current_address_months_count', 'session_length_in_minutes', 'device_distinct_emails_8w']\n",
    "\n",
    "    medians = df_train_imputed[columns_to_impute].median()\n",
    "\n",
    "    for column in columns_to_impute:\n",
    "        df_train_imputed[column] = df_train_imputed[column].fillna(medians[column])\n",
    "        df_test_imputed[column] = df_test_imputed[column].fillna(medians[column])\n",
    "\n",
    "    # Step 2: Bank months count - fill missing with 0 and track missing values\n",
    "    df_train_imputed['bank_months_count_was_missing'] = df_train_imputed['bank_months_count'].isna().astype(int)\n",
    "    df_test_imputed['bank_months_count_was_missing'] = df_test_imputed['bank_months_count'].isna().astype(int)\n",
    "\n",
    "    df_train_imputed['bank_months_count'] = df_train_imputed['bank_months_count'].fillna(0)\n",
    "    df_test_imputed['bank_months_count'] = df_test_imputed['bank_months_count'].fillna(0)\n",
    "\n",
    "    # Step 3: Bucket-Based Imputation for prev_address_months_count\n",
    "    bin_edges = pd.cut(df_train_imputed['current_address_months_count'], 12, retbins=True)[1]\n",
    "\n",
    "    df_train_imputed['current_address_bucket'] = pd.cut(df_train_imputed['current_address_months_count'], bins=bin_edges)\n",
    "    df_test_imputed['current_address_bucket'] = pd.cut(df_test_imputed['current_address_months_count'], bins=bin_edges)\n",
    "\n",
    "    # Compute medians for each bucket\n",
    "    bucket_medians = df_train_imputed.groupby('current_address_bucket')['prev_address_months_count'].median()\n",
    "\n",
    "    # Indicator column for missing values\n",
    "    df_train_imputed['prev_address_months_count_was_missing'] = df_train_imputed['prev_address_months_count'].isna().astype(int)\n",
    "    df_test_imputed['prev_address_months_count_was_missing'] = df_test_imputed['prev_address_months_count'].isna().astype(int)\n",
    "\n",
    "    # Train set: fill missing using bucket median\n",
    "    df_train_imputed['prev_address_months_count'] = df_train_imputed.groupby('current_address_bucket')['prev_address_months_count'].transform(\n",
    "        lambda x: x.fillna(x.median())\n",
    "    )\n",
    "\n",
    "    # Test set: apply training bucket medians\n",
    "    df_test_imputed['prev_address_months_count'] = df_test_imputed.apply(\n",
    "        lambda row: bucket_medians[row['current_address_bucket']]\n",
    "        if pd.isna(row['prev_address_months_count']) and row['current_address_bucket'] in bucket_medians\n",
    "        else row['prev_address_months_count'],\n",
    "        axis=1\n",
    "    )\n",
    "\n",
    "    # Drop temporary bucket column\n",
    "    df_train_imputed.drop(columns=['current_address_bucket'], inplace=True)\n",
    "    df_test_imputed.drop(columns=['current_address_bucket'], inplace=True)\n",
    "\n",
    "    # Validate that all missing values are handled\n",
    "    print(\"Train set null values after imputation:\")\n",
    "    print(df_train_imputed[missing_value_cols].isna().sum())\n",
    "\n",
    "    print(\"\\nTest set null values after imputation:\")\n",
    "    print(df_test_imputed[missing_value_cols].isna().sum())\n",
    "    print(f\"Training set shape after imputation: {df_train_imputed.shape}\")\n",
    "    print(f\"Test set shape after imputation: {df_test_imputed.shape}\")\n",
    "\n",
    "    return df_train_imputed, df_test_imputed"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3592bf6f-0dea-452d-99f9-ff1312f2876a",
   "metadata": {},
   "source": [
    "## 3. One-hot encode for categorical features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "73df9d73-255e-4361-a96e-bc6919dac370",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "def one_hot_encode(X_train, X_test, categorical_features):\n",
    "    \"\"\"\n",
    "    Applies one-hot encoding to categorical features in the dataset.\n",
    "\n",
    "    - Identifies categorical features (dtype = 'object')\n",
    "    - Uses OneHotEncoder to transform categorical features\n",
    "    - Merges encoded columns with numerical features\n",
    "    - Ensures consistent encoding across train and test sets\n",
    "\n",
    "    Parameters:\n",
    "    X_train (pd.DataFrame): Training dataset\n",
    "    X_test (pd.DataFrame): Test dataset\n",
    "\n",
    "    Returns:\n",
    "    pd.DataFrame, pd.DataFrame: One-hot encoded training and test datasets\n",
    "    \"\"\"\n",
    "\n",
    "    # Identify categorical features\n",
    "    # categorical_features = [col for col in X_train.columns if X_train[col].nunique < 'object']\n",
    "    print(\"Features to encode:\", categorical_features)\n",
    "\n",
    "    if not categorical_features:\n",
    "        print(\"No categorical features found. Skipping one-hot encoding.\")\n",
    "        return X_train, X_test\n",
    "\n",
    "    # Initialize one-hot encoder\n",
    "    ohe = OneHotEncoder(sparse_output=False, handle_unknown='ignore')\n",
    "\n",
    "    # Encode training and test sets\n",
    "    ohe_X_train = pd.DataFrame(ohe.fit_transform(X_train[categorical_features]))\n",
    "    ohe_X_test = pd.DataFrame(ohe.transform(X_test[categorical_features]))\n",
    "\n",
    "    # Set index to match original data\n",
    "    ohe_X_train.index = X_train.index\n",
    "    ohe_X_test.index = X_test.index\n",
    "\n",
    "    # Set column names to match encoded feature names\n",
    "    ohe_feature_names = ohe.get_feature_names_out(input_features=categorical_features)\n",
    "    ohe_X_train.columns = ohe_feature_names\n",
    "    ohe_X_test.columns = ohe_feature_names\n",
    "\n",
    "    # Drop categorical features and concatenate with encoded data\n",
    "    num_X_train = X_train.drop(categorical_features, axis=1)\n",
    "    num_X_test = X_test.drop(categorical_features, axis=1)\n",
    "\n",
    "    X_train_encoded = pd.concat([num_X_train, ohe_X_train], axis=1)\n",
    "    X_test_encoded = pd.concat([num_X_test, ohe_X_test], axis=1)\n",
    "\n",
    "    print(f\"One-hot encoded training shape: {X_train_encoded.shape}\")\n",
    "    print(f\"One-hot encoded test shape: {X_test_encoded.shape}\")\n",
    "\n",
    "    return X_train_encoded, X_test_encoded"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f3bdc22-9d36-4f73-8a40-e4f0e3ee8dde",
   "metadata": {},
   "source": [
    "# 4. Binning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3c1ee82-216c-47af-abf3-e2d2cf2028b9",
   "metadata": {},
   "source": [
    "Binning the bank_months_count, to turn it into a categorical variable for lower cardinality. \n",
    "\n",
    "Don't want to bin any other features as we don't want to lose details of the data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "06a19bfb-2514-4cb2-8a76-a166b18d18c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def bin_bank_months_count(X_train, X_test, y_train):\n",
    "    \"\"\"\n",
    "    Bins the 'bank_months_count' feature into custom intervals and replaces them with pre-defined medians.\n",
    "\n",
    "    - First bin includes only 0, the rest are grouped in intervals of 4\n",
    "    - Applies binning to both training and test datasets\n",
    "    - Plots fraud proportion against binned values\n",
    "    - Drops the original 'bank_months_count' column after transformation\n",
    "\n",
    "    Parameters:\n",
    "    X_train (pd.DataFrame): Training dataset\n",
    "    X_test (pd.DataFrame): Test dataset\n",
    "    y_train (pd.Series): Target variable for training set (needed for visualization)\n",
    "\n",
    "    Returns:\n",
    "    pd.DataFrame, pd.DataFrame: Training and test datasets with binned 'bank_months_count'\n",
    "    \"\"\"\n",
    "\n",
    "    # Make copies to avoid modifying original datasets\n",
    "    X_train_binned = X_train.copy()\n",
    "    X_test_binned = X_test.copy()\n",
    "\n",
    "    min_val = X_train_binned[\"bank_months_count\"].min()\n",
    "    print(f\"the minimum value of bank_months_count is {min_val}\")\n",
    "    # Define bins: First bin starts from min_val, and remaining are in intervals of 4\n",
    "    bins = [min_val, min_val + 1] + [i for i in range(int(min_val) + 5, 37, 4)]\n",
    "    \n",
    "    median_labels = [0, 2.5, 6.5, 10.5, 14.5, 18.5, 22.5, 26.5, 30.5]  # Median of each bin\n",
    "\n",
    "    print(\"\\n Bin Ranges:\")\n",
    "    for i in range(len(bins) - 1):\n",
    "        print(f\"Bin {i+1}: [{bins[i]}, {bins[i+1]}) -> Median: {median_labels[i]}\")\n",
    "\n",
    "    # Apply binning transformation\n",
    "    X_train_binned[\"bank_months_count_binned\"] = pd.cut(\n",
    "        X_train_binned[\"bank_months_count\"], bins=bins, labels=median_labels, include_lowest=True, right=False\n",
    "    ).astype(float)\n",
    "\n",
    "    X_test_binned[\"bank_months_count_binned\"] = pd.cut(\n",
    "        X_test_binned[\"bank_months_count\"], bins=bins, labels=median_labels, include_lowest=True, right=False\n",
    "    ).astype(float)\n",
    "\n",
    "    # Display bin distribution\n",
    "    bin_counts = X_train_binned[\"bank_months_count_binned\"].value_counts().sort_index()\n",
    "    print(\"\\n Bin medians and counts in training set:\\n\")\n",
    "    print(bin_counts)\n",
    "\n",
    "    # Visualization: Fraud proportion per bin\n",
    "    X_train_binned[\"fraud_bool\"] = y_train  # Temporarily add fraud labels for visualization\n",
    "    fraud_proportion = X_train_binned.groupby(\"bank_months_count_binned\")[\"fraud_bool\"].mean()\n",
    "\n",
    "    plot_data = (\n",
    "        X_train_binned[X_train_binned[\"fraud_bool\"] == 1][\"bank_months_count_binned\"]\n",
    "        .value_counts(normalize=True)\n",
    "        .sort_index()\n",
    "    )\n",
    "\n",
    "    # Plot fraud proportion per bin\n",
    "    plt.figure(figsize=(8, 4))\n",
    "    plot_data.plot(kind=\"bar\", color=\"#fc8d62\", edgecolor=\"black\")\n",
    "    plt.xlabel(\"Bank Months Count (Binned)\")\n",
    "    plt.ylabel(\"Proportion of Fraud (fraud_bool = 1)\")\n",
    "    plt.title(\"Proportion of Fraud by Bank Months Count (Binned)\")\n",
    "    plt.xticks(rotation=45)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(\"fraud_by_bank_month_count.png\")\n",
    "    plt.show()\n",
    "    \n",
    "\n",
    "    # Remove temporary fraud column\n",
    "    X_train_binned.drop(columns=[\"fraud_bool\"], inplace=True)\n",
    "\n",
    "    # Drop original 'bank_months_count' after binning\n",
    "    X_train_binned.drop(columns=\"bank_months_count\", inplace=True)\n",
    "    X_test_binned.drop(columns=\"bank_months_count\", inplace=True)\n",
    "\n",
    "    print(f\"Final shape after binning - Train: {X_train_binned.shape}, Test: {X_test_binned.shape}\")\n",
    "\n",
    "    return X_train_binned, X_test_binned"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ec763a6-6cf3-415c-8655-36f5a6cd9c3c",
   "metadata": {},
   "source": [
    "# 5. Scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "94e76e65-970d-41c4-a292-9b5fb244a4b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import RobustScaler\n",
    "\n",
    "def robust_scaler(X_train, X_test):\n",
    "    \"\"\"\n",
    "    Apply robust scaler on numerical features. Robust scaler scale the data based on IQR and median, \n",
    "    which maeks the dataset more robust against outliers. https://proclusacademy.com/blog/robust-scaler-outliers/ \n",
    "\n",
    "    - First split the dataset into numerical and categorical features. \n",
    "    - Then import RobustScaler from sklearn\n",
    "    - Fit robust scaler on the training set, then transform numerical_features in both training and test set. \n",
    "    - Add a 'scaled_' prefix to the columns that are scaled, then drop the original column.\n",
    "\n",
    "    Parameters:\n",
    "    X_train (pd.DataFrame): Training dataset\n",
    "    X_test (pd.DataFrame): Test dataset\n",
    "\n",
    "    Returns:\n",
    "    pd.DataFrame, pd.DataFrame: Training and test datasets with scaled numerical features\n",
    "    \"\"\"\n",
    "    categorical_features, numerical_features = split_num_cat(X_train)\n",
    "    print('Categorical features:', categorical_features)\n",
    "    print('Numerical features:', numerical_features)\n",
    "    \n",
    "    X_train[numerical_features].describe()\n",
    "    \n",
    "    X_train_scaled = X_train.copy()\n",
    "    X_test_scaled = X_test.copy()\n",
    "     \n",
    "    robust_scaler = RobustScaler()\n",
    "    \n",
    "    scaled_train = robust_scaler.fit_transform(X_train_scaled[numerical_features])\n",
    "    scaled_test = robust_scaler.transform(X_test_scaled[numerical_features])\n",
    "    \n",
    "    # add new columns scaled features while keeping the original feature with the unscaled values. \n",
    "    for i, feature in enumerate(numerical_features):\n",
    "        X_train_scaled['scaled_' + feature] = scaled_train[:, i]\n",
    "        X_test_scaled['scaled_' + feature] = scaled_test[:, i]\n",
    "    \n",
    "    print(X_train_scaled.describe())\n",
    "    \n",
    "    # drop the original columns before scaling:\n",
    "    X_train_scaled.drop(columns=numerical_features, inplace=True)\n",
    "    X_test_scaled.drop(columns=numerical_features, inplace=True)\n",
    "\n",
    "    print(f\"Final shape after binning - Train: {X_train_scaled.shape}, Test: {X_test_scaled.shape}\")\n",
    "\n",
    "    return X_train_scaled, X_test_scaled"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a44b7e8-1466-4d3b-9aa7-467598bebd3d",
   "metadata": {},
   "source": [
    "help with unsupervised learning, minimise bias against one variabel "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41da9e85-eae9-4d5d-9a78-c475782f4721",
   "metadata": {},
   "source": [
    "# 6. Handle outliers - not used"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "536b879e-f243-411e-b318-4e15db159f2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_outliers(series):\n",
    "    Q1 = series.quantile(0.25)\n",
    "    Q3 = series.quantile(0.75)\n",
    "    IQR = Q3 - Q1\n",
    "    lower_bound = Q1 - 1.5 * IQR\n",
    "    upper_bound = Q3 + 1.5 * IQR\n",
    "    return (series < lower_bound) | (series > upper_bound)\n",
    "\n",
    "def handle_outliers(X_train, y_train):\n",
    "    categorical_features, numerical_features = split_num_cat(X_train)\n",
    "    print('Categorical features:', categorical_features)\n",
    "    print('Numerical features:', numerical_features)\n",
    "\n",
    "    # Detect outliers in numerical features\n",
    "    total_outliers = X_train[numerical_features].apply(detect_outliers).sum()\n",
    "    outlier_percentage = (total_outliers / len(X_train)) * 100\n",
    "    print(\"Percentage of outliers per numerical variable\\n\", outlier_percentage)\n",
    "\n",
    "    # For all fraud cases, calculate the percentage of outliers\n",
    "    X_train_fraud_only = X_train[y_train == 1].copy()\n",
    "    total_outlier_fraud_only = detect_outliers(X_train_fraud_only[numerical_features]).sum()\n",
    "    outlier_percentages_fraud_only = (total_outlier_fraud_only / len(X_train_fraud_only)) * 100\n",
    "    print(\"Percentage of outliers among the fraud cases (fraud_bool = 1):\")\n",
    "    print(outlier_percentages_fraud_only)\n",
    "\n",
    "    # Calculate fraud outlier percentages per feature\n",
    "    outlier_fraud_percentages = {}\n",
    "    for feature in numerical_features:\n",
    "        outliers = detect_outliers(X_train[feature])\n",
    "        fraud_outliers = X_train.loc[outliers & (y_train == 1), feature]\n",
    "        percentage_fraud_outliers = (len(fraud_outliers) / len(X_train[X_train[feature].notna()])) * 100\n",
    "        outlier_fraud_percentages[feature] = percentage_fraud_outliers\n",
    "    print(\"Percentage of outliers that are fraud:\")\n",
    "    print(outlier_fraud_percentages)\n",
    "\n",
    "    # Remove outliers using the 1st and 99th percentile\n",
    "    q1 = X_train[numerical_features].quantile(0.01)\n",
    "    q99 = X_train[numerical_features].quantile(0.99)\n",
    "    X_train_cleaned = X_train[(X_train[numerical_features] >= q1).all(axis=1) &\n",
    "                              (X_train[numerical_features] <= q99).all(axis=1)]\n",
    "    y_train_cleaned = y_train.loc[X_train_cleaned.index].copy()\n",
    "\n",
    "    # Print percentage of retained data\n",
    "    percentage_retained = (len(X_train_cleaned) / len(X_train)) * 100\n",
    "    print(f\"Percentage of data retained after dropping outliers: {percentage_retained:.2f}%\")\n",
    "\n",
    "    # Calculate percentage of fraud cases retained\n",
    "    fraud_indices = y_train[y_train == 1].index\n",
    "    fraud_retained = len(fraud_indices.intersection(X_train_cleaned.index))\n",
    "    percentage_fraud_retained = (fraud_retained / len(fraud_indices)) * 100\n",
    "    print(f\"Percentage of fraud_bool = 1 retained in cleaned data: {percentage_fraud_retained:.2f}%\")\n",
    "    \n",
    "    print(f\"Final X_train shape: {X_train_cleaned.shape}\")\n",
    "    print(f\"Final y_train shape: {y_train_cleaned.shape}\")\n",
    "\n",
    "    return X_train_cleaned, y_train_cleaned"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7f63a00-2d1a-4ea9-9944-a946d340d802",
   "metadata": {},
   "source": [
    "# Handle imbalance with SMOTE, only on the training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a604c34d-661c-4c86-949f-d43cb0a0009f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "from imblearn.over_sampling import SMOTENC\n",
    "# from imblearn.over_sampling import SMOTE\n",
    "# from imblearn.under_sampling import RandomUnderSampler\n",
    "def smote(X_train, y_train, over_ratio=0.7):\n",
    "    categorical_features, numerical_features = split_num_cat(X_train)\n",
    "    print(f\"Before SMOTE: {Counter(y_train)}\")\n",
    "    print(f\"Before SMOTE, shape of the training set: {X_train.shape}\")\n",
    "    \n",
    "    sm = SMOTENC(categorical_features=categorical_features, random_state=123, sampling_strategy=over_ratio)\n",
    "    X_train_smote, y_train_smote = sm.fit_resample(X_train, y_train)\n",
    "    \n",
    "    print(f\"After oversampling: {Counter(y_train_smote)}\")\n",
    "    print(f\"After oversampling, shape of the training set: {X_train_smote.shape}\")\n",
    "\n",
    "    return X_train_smote, y_train_smote\n",
    "\n",
    "# def smote(X_train, y_train, over_ratio=0.8, under_ratio=1.0):\n",
    "#     \"\"\"\n",
    "#     Applies SMOTE for oversampling and RandomUnderSampler for undersampling.\n",
    "    \n",
    "#     :param X_train: Feature matrix.\n",
    "#     :param y_train: Target vector.\n",
    "#     :param over_ratio: Oversampling ratio for the minority class (default: 0.8).\n",
    "#     :param under_ratio: Undersampling ratio for the majority class after oversampling (default: 1.0).\n",
    "#     :return: Resampled X_train and y_train.\n",
    "#     \"\"\"\n",
    "#     print(f\"Before SMOTE: {Counter(y_train)}\")\n",
    "#     print(f\"Before SMOTE, shape of the training set: {X_train.shape}\")\n",
    "\n",
    "    # # Oversample the minority class\n",
    "    # over = SMOTE(sampling_strategy=over_ratio, random_state=2)\n",
    "    # X_train_res, y_train_res = over.fit_resample(X_train, y_train)\n",
    "\n",
    "    # print(f\"After oversampling: {Counter(y_train_res)}\")\n",
    "\n",
    "    # # Undersample the majority class\n",
    "    # under = RandomUnderSampler(sampling_strategy=under_ratio, random_state=2)\n",
    "    # X_train_resampled, y_train_resampled = under.fit_resample(X_train_res, y_train_res)\n",
    "\n",
    "    # print(f\"After undersampling: {Counter(y_train_resampled)}\")\n",
    "    # print(f\"After undersampling, shape of the training set: {X_train_resampled.shape}\")\n",
    "\n",
    "    # return X_train_resampled, y_train_resampled"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7eb95d14-642c-4ed4-8d26-502a84540dda",
   "metadata": {},
   "source": [
    "## Mutual Information and chi2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f4b1c6dd-ccdf-465d-9407-69687ed1fbaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.feature_selection import mutual_info_regression, chi2, SelectKBest\n",
    "\n",
    "def mutual_information(X_train, y_train):\n",
    "    \"\"\"\n",
    "    Compute Mutual Information scores for all features.\n",
    "    \"\"\"\n",
    "    X = X_train.copy()\n",
    "    y = y_train.copy()\n",
    "\n",
    "    # Label encode categorical features\n",
    "    for colname in X.select_dtypes([\"category\", \"object\"]):\n",
    "        X[colname], _ = X[colname].factorize()\n",
    "\n",
    "    # Determine discrete features\n",
    "    discrete_features = X.dtypes == int\n",
    "\n",
    "    # Compute Mutual Information scores\n",
    "    mi_scores = mutual_info_regression(X, y, discrete_features=discrete_features)\n",
    "    mi_scores = pd.Series(mi_scores, name=\"MI Scores\", index=X.columns).sort_values(ascending=False)\n",
    "\n",
    "    print(\"Mutual Information Scores:\")\n",
    "    print(mi_scores)\n",
    "\n",
    "    def plot_mi_scores(scores):\n",
    "        scores = scores.sort_values(ascending=True)\n",
    "        width = np.arange(len(scores))\n",
    "        ticks = list(scores.index)\n",
    "        plt.barh(width, scores)\n",
    "        plt.yticks(width, ticks)\n",
    "        plt.title(\"Mutual Information Scores\")\n",
    "        plt.savefig(\"mi_scores.png\", dpi=300, bbox_inches=\"tight\")\n",
    "        plt.show()\n",
    "\n",
    "    plt.figure(dpi=100, figsize=(12, 16))\n",
    "    plot_mi_scores(mi_scores)\n",
    "\n",
    "    return mi_scores\n",
    "\n",
    "\n",
    "def chi2_test(X_train, y_train):\n",
    "    \"\"\"\n",
    "    Perform Chi-Square test for categorical features.\n",
    "    \"\"\"\n",
    "    categorical_features, numerical_features = split_num_cat(X_train)\n",
    "    X_cat = X_train[categorical_features].copy()\n",
    "    chi2_test = SelectKBest(score_func=chi2).fit(X_cat, y_train)\n",
    "\n",
    "    chi2_output = pd.DataFrame({\n",
    "        'feature': X_cat.columns,\n",
    "        'chi2_score': chi2_test.scores_,\n",
    "        'p_value': chi2_test.pvalues_\n",
    "    }).sort_values(by=['p_value'])\n",
    "\n",
    "    print(\"Chi-Square Test Results:\")\n",
    "    print(chi2_output)\n",
    "\n",
    "    # Filter significant features\n",
    "    chi2_output_significant = chi2_output[chi2_output['p_value'] <= 0.05]\n",
    "\n",
    "    # Plot significant chi2 scores\n",
    "    plt.figure(figsize=(15, 10))\n",
    "    sns.barplot(data=chi2_output_significant, x='chi2_score', y='feature')\n",
    "    plt.title(\"Significant Chi-Square Scores\")\n",
    "    plt.savefig(\"chi_square.png\", dpi=300, bbox_inches=\"tight\")\n",
    "    plt.show()\n",
    "\n",
    "    return chi2_output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1116d0a1-847b-41ba-b5b5-78637543f3ff",
   "metadata": {},
   "source": [
    "MI can help you to understand the relative potential of a feature as a predictor of the target, considered by itself.\n",
    "It's possible for a feature to be very informative when interacting with other features, but not so informative all alone. MI can't detect interactions between features. It is a univariate metric.\n",
    "The actual usefulness of a feature depends on the model you use it with. A feature is only useful to the extent that its relationship with the target is one your model can learn. Just because a feature has a high MI score doesn't mean your model will be able to do anything with that information. You may need to transform the feature first to expose the association."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9d26da8-ce0e-4de8-ab84-bbe249ea1306",
   "metadata": {},
   "source": [
    "# Finalize data for training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "90e2b29a-138a-4820-8696-04fcaca0368d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def export_final_df(X_train, y_train, X_test, y_test, data_folder, \n",
    "                    x_train_filename, y_train_filename, \n",
    "                    x_test_filename, y_test_filename):\n",
    "    bool_features = [col for col in X_train.columns if X_train[col].dtypes == 'bool']\n",
    "    X_train[bool_features] = X_train[bool_features].astype(\"int\")\n",
    "    y_train = y_train.astype(\"int\")\n",
    "    X_test[bool_features] = X_test[bool_features].astype(\"int\")\n",
    "    y_test = y_test.astype(\"int\")\n",
    "\n",
    "    print(f'Final X_train shape {X_train.shape}')\n",
    "    print(f'Final y_train shape {y_train.shape}')\n",
    "    print(f'Final X_test shape {X_test.shape}')\n",
    "    print(f'Final y_test shape {y_test.shape}')\n",
    "\n",
    "    print(\"Feature engineering is done. Exporting the final training and test data to:\", data_folder)\n",
    "\n",
    "    X_train.to_csv(f\"{data_folder}/{x_train_filename}\", index=True)\n",
    "    print(f'{x_train_filename}is exported to {data_folder}')\n",
    "    \n",
    "    X_test.to_csv(f\"{data_folder}/{x_test_filename}\")\n",
    "    print(f'{x_test_filename}is exported to {data_folder}')\n",
    "    \n",
    "    y_train.to_csv(f\"{data_folder}/{y_train_filename}\")\n",
    "    print(f'{y_train_filename}is exported to {data_folder}')\n",
    "    \n",
    "    y_test.to_csv(f\"{data_folder}/{y_test_filename}\")\n",
    "    print(f'{y_test_filename}is exported to {data_folder}')\n",
    "\n",
    "    print(\"Data successfully exported into CSV!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a79dbde3-d832-4270-83ac-fa04818957da",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
