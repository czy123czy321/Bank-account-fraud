{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b80c5648-0c00-467c-b639-c5e68298d374",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'data_location': '/Users/zoe/Documents/Bank-account-fraud/data',\n",
       " 'output_location': '/Users/zoe/Documents/Bank-account-fraud/output'}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import yaml\n",
    "with open (\"/Users/zoe/Documents/Bank-account-fraud/params.yaml\") as p:\n",
    "    params = yaml.safe_load(p)\n",
    "params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "25e8de4b-a7f1-4f4f-9e6c-8299a2a4840c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "pd.set_option('display.max_columns', 500)\n",
    "import warnings as wr\n",
    "wr.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d4b5edcc-38a5-49b0-87a5-42d352bf158b",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = pd.read_csv(f\"{params['data_location']}/x_train_data.csv\", index_col=0)\n",
    "y_train = pd.read_csv(f\"{params['data_location']}/y_train_data.csv\", index_col=0)\n",
    "X_test = pd.read_csv(f\"{params['data_location']}/x_test_data.csv\", index_col=0)\n",
    "y_test = pd.read_csv(f\"{params['data_location']}/y_test_data.csv\", index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f4f572e-87dd-4fab-b96b-23d31dda5015",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c097a77d-bcfe-4886-838f-184fc0386861",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8836c4c0-a7c5-499c-b83a-008af3d72380",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e2c4f81-d66c-486b-ad2e-02d744d8a61c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "0155834e-bfc6-4bfc-9759-f4ece3975ff4",
   "metadata": {},
   "source": [
    "# Baseline model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9177b828-0436-4c1c-9648-3562ab2a1c3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "5d367c4d-0036-4eaf-84fa-9968967a8f15",
   "metadata": {},
   "outputs": [],
   "source": [
    "# imbalaned dataset with low percentage of positive cases\n",
    "#Â use AUC as the measuring metrics\n",
    "# assume it's more costly to have higher FN(misclassified fraud cases as not fraud) than higher FP (false alarm for not fraud as fraud)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "accdd6cc-72a9-4c80-b92b-2520b3a80b76",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_auc_score, confusion_matrix, roc_curve\n",
    "\n",
    "def baseline_model_score(X, y, model):\n",
    "    \"\"\"\n",
    "    Function to compute the AUC of the baseline model and compare FN and FP costs.\n",
    "    \n",
    "    Parameters:\n",
    "        X: DataFrame with the training features\n",
    "        y: Series with the true labels (fraud_bool)\n",
    "        model: The model to be evaluated (must have a 'predict_proba' method)\n",
    "        \n",
    "    Returns:\n",
    "        auc_score: AUC score of the model\n",
    "        fn_cost: The number of false negatives for the given model\n",
    "        fp_cost: The number of false positives for the given model\n",
    "    \"\"\"\n",
    "    for colname in X.select_dtypes([\"category\", \"object\"]):\n",
    "        X[colname], _ = X[colname].factorize()\n",
    "        \n",
    "    model.fit(X, y)\n",
    "    \n",
    "    # Predict probabilities of the positive class (fraud) using the model\n",
    "    probs = model.predict_proba(X)[:, 1]\n",
    "    \n",
    "    # AUC score\n",
    "    auc_score = roc_auc_score(y, probs)\n",
    "    \n",
    "    # Predicted classes using a threshold of 0.5\n",
    "    y_pred = (probs >= 0.5).astype(int)\n",
    "    \n",
    "    # Confusion matrix (True Positives, False Positives, False Negatives, True Negatives)\n",
    "    tn, fp, fn, tp = confusion_matrix(y, y_pred).ravel()\n",
    "    fpr, tpr, thresholds = roc_curve(y, probs)\n",
    "    \n",
    "    print(f\"AUC: {auc_score:.4f}\")\n",
    "    print(f\"True Positive Rate (FNR/recall): {tp/(tp+fn)}\")\n",
    "    print(f\"False Positives Rate (FPR): {fp/(tn+fp)}\")\n",
    "    \n",
    "    return auc_score, fpr, tpr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "140b65b3-59e1-4a98-8b6c-4a95f482960a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC: 0.9537\n",
      "True Positive Rate (FNR): 0.10112107623318385\n",
      "False Positives Rate (FPR): 0.00023385751125044242\n"
     ]
    }
   ],
   "source": [
    "model = XGBClassifier()\n",
    "auc_score, fpr, tpr,  = baseline_model_score(X_train, y_train, model=model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7b44ab0-e280-447b-b446-87f47943db07",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
